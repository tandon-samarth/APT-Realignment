{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Geomtries with Parcel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import geopandas as gpd\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from shapely.geometry import box\n",
    "from pyproj import Geod\n",
    "from matplotlib import pyplot as plt\n",
    "import sys \n",
    "sys.path.append('/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/src/apt_realignment')\n",
    "from utils.geometric_utils import read_vector_data, create_logger, get_nearest_poly , prep_polygons_asarr,download_osm_building_footprint\n",
    "from utils.haversine_distance import get_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geod = Geod(ellps=\"WGS84\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from os import stat\n",
    "from os.path import isfile\n",
    "\n",
    "data_path  = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/BFP_Analysis_USA/data/data\"\n",
    "state = \"CT\"\n",
    "city = \"hartford\"\n",
    "parcel_dir = \"Parcels_09003\"\n",
    "\n",
    "apt_data_path = os.path.join(data_path,state,\"APT_2022_09_000_nam_usa_utx.shp\" )\n",
    "parcel_path = os.path.join(data_path,state,city,\"{}/{}.shp\".format(parcel_dir,parcel_dir))\n",
    "msft_building = os.path.join(data_path,state,'Connecticut.geojson')\n",
    "osm_building = os.path.join(data_path,state,city,'building_footprint.shp')\n",
    "\n",
    "print(\"APT data path :\",apt_data_path)\n",
    "print(\"Parcel Data:\",parcel_path)\n",
    "print(\"Building_geojson: \",msft_building)\n",
    "print(\"OSM building footprint: \",osm_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bfp_parcel_overlap(land_parcels,building_footprints):\n",
    "    \n",
    "    print(\"Reading Land Parcel data .. \")\n",
    "    land_parcel_df = read_vector_data(land_parcels)\n",
    "    print(\"Reading Building Footprints ..  \")\n",
    "    footprint_df = read_vector_data(building_footprints)\n",
    "    \n",
    "    print(\"creating sjoin of land Parcel data and Building Footprints.. \")\n",
    "    building_within_parcel_df = gpd.sjoin(land_parcel_df, footprint_df, op='intersects', how='left')\n",
    "    building_within_parcel_df = building_within_parcel_df.dropna()  # drop columns with no Buildings\n",
    "\n",
    "    def __get_buildingfootprint(val):\n",
    "        return footprint_df['geometry'].loc[val]\n",
    "\n",
    "    def __get_building_roi(data: gpd.GeoSeries):\n",
    "        building_polygon = data['building_geometry']\n",
    "        parcel_polygon = data['geometry']\n",
    "        building_roi = None\n",
    "        try:\n",
    "            if building_polygon == np.nan:\n",
    "                building_roi = parcel_polygon\n",
    "            if building_polygon.area > parcel_polygon.area:\n",
    "                building_roi = parcel_polygon.intersection(building_polygon)\n",
    "            else:\n",
    "                building_roi = building_polygon\n",
    "        except:\n",
    "            logging.error(\"error for {},{}\".format(building_polygon, parcel_polygon))\n",
    "        return building_roi\n",
    "\n",
    "    building_within_parcel_df['building_geometry'] = building_within_parcel_df['index_right'].apply(lambda x: __get_buildingfootprint(x))\n",
    "\n",
    "    building_within_parcel_df['building_roi'] = building_within_parcel_df.apply(lambda x: __get_building_roi(x), axis=1)\n",
    "    building_within_parcel_df = building_within_parcel_df.drop(['index_right', 'release'],axis=1)\n",
    "    building_within_parcel_df = building_within_parcel_df.dropna()\n",
    "    return building_within_parcel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge OSM and MSFT_building footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(osm_building):\n",
    "    download_osm_building_footprint(county=city,state=state,out_path=osm_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_osm_msft_data(msft_geojson,osm_geojson):\n",
    "    osm_gdf = read_vector_data(osm_geojson)\n",
    "    osm_bounds = box(*osm_gdf.total_bounds)\n",
    "\n",
    "    msft_df = read_vector_data(msft_geojson)\n",
    "    msft_df = msft_df.reset_index()\n",
    "\n",
    "    osm_in_msft_df = gpd.sjoin(osm_gdf,msft_df, op='intersects', how='left')\n",
    "    merged_data = osm_in_msft_df['geometry']\n",
    "\n",
    "    def check_within_bounds(x):\n",
    "        geo_polygon = None\n",
    "        if osm_bounds.contains(x):\n",
    "            geo_polygon = x\n",
    "        return geo_polygon\n",
    "\n",
    "    msft_geometries = msft_df.loc[~msft_df['index'].isin(osm_in_msft_df['index_right'].values)]['geometry']\n",
    "    final_geometries = msft_geometries.apply(lambda x: check_within_bounds(x))\n",
    "    final_gdf = merged_data.append(final_geometries[final_geometries.notna()])\n",
    "    return final_gdf\n",
    "\n",
    "merged_data = merge_osm_msft_data(msft_building,osm_building)\n",
    "merged_data.to_file(os.path.join(data_path,state,city,'msft_osm_building_footprint.shp'), driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data = merge_osm_msft_data(msft_building,county='bexar',state= 'Texas')\n",
    "print(merged_data.shape)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Land Parcels and Building footprints\n",
    "\n",
    "This code read the parcel and building footprint data and finds out sjoin of both geometries . It rejects the data where building footprints is not found ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_bfp_df = get_bfp_parcel_overlap(land_parcels=parcel_path,building_footprints=msft_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_bfp_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get BFP within Parcel data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_within_parcel_count = parcel_bfp_df.groupby('PRCLDMPID')['geometry'].count()\n",
    "# building_within_parcel_count.hist(bins=np.arange(0,10,1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,9))\n",
    "\n",
    "ax.set_title(\"Histogram of APT to centroid distance on/not on BFP\")\n",
    "ax.set_xlabel(\"APT point to centroid distance(meters)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "frqTrue, edgesTrue = np.histogram(building_within_parcel_count, bins = np.arange(1,10,1))\n",
    "p1 = ax.bar(edgesTrue[:-1], frqTrue, width=np.diff(edgesTrue), edgecolor=\"black\", align=\"edge\",alpha=0.4,label='Address Points on Rooftop',color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buildings_within_parcel(data: gpd.GeoSeries, count=None):\n",
    "    print(\"Acquiring BFP's within land Parcels \".format(count))\n",
    "    building_within_parcel_count = data.groupby('PRCLDMPID')['geometry'].count()\n",
    "    if count == 1:\n",
    "        parcel_ids_with_one_building = list(building_within_parcel_count[building_within_parcel_count == 1].keys())\n",
    "        filtered_dataframe = data[data['PRCLDMPID'].isin(parcel_ids_with_one_building)]\n",
    "    elif count == 2:\n",
    "        parcel_ids_with_two_buildings = list(building_within_parcel_count[building_within_parcel_count == 2].keys())\n",
    "        filtered_dataframe = data[data['PRCLDMPID'].isin(parcel_ids_with_two_buildings)]\n",
    "    else:\n",
    "        parcel_ids_with_n_buildings = list(building_within_parcel_count[building_within_parcel_count > 2].keys())\n",
    "        filtered_dataframe = data[data['PRCLDMPID'].isin(parcel_ids_with_n_buildings)]\n",
    "    return filtered_dataframe\n",
    "\n",
    "df_parcel_within_bfp = get_buildings_within_parcel(parcel_bfp_df, count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data shape\",df_parcel_within_bfp.shape)\n",
    "df_parcel_within_bfp.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parcel_within_bfp = df_parcel_within_bfp.drop(['index_right','release'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Anchor point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parcel_anchorpoints(anchor_points_data,input_dataframe: gpd.GeoSeries):\n",
    "    print(\"Reading Anchor-Points data over Parcel-Building Geo-Dataframe\")\n",
    "    \n",
    "    anchorpoint_df = read_vector_data(anchor_points_data)\n",
    "    apt_df_columns = list(anchorpoint_df.columns)\n",
    "    \n",
    "    print(\"Processing Anchor-Points and Parcel-Building Geo-Dataframe\")\n",
    "    # find spatial join of input_dataframe with anchorpoint\n",
    "    grouped_df = gpd.sjoin(input_dataframe, anchorpoint_df, op='contains', how='inner')\n",
    "    print(grouped_df.keys())\n",
    "\n",
    "    def _get_apt_point(val):\n",
    "        return anchorpoint_df['geometry'].loc[val]\n",
    "\n",
    "    grouped_df['APT'] = grouped_df['index_right'].apply(lambda x: _get_apt_point(x))\n",
    "    grouped_df = grouped_df.drop(['index_right'], axis=1)\n",
    "    return grouped_df , apt_df_columns\n",
    "\n",
    "process_df , cols = get_parcel_anchorpoints(apt_data_path,df_parcel_within_bfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Required columns\",cols)\n",
    "process_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_point_on_polygon(bfp_polygon, apt_point):\n",
    "    flag = False\n",
    "    if bfp_polygon.contains(apt_point):\n",
    "        flag = True\n",
    "    return flag\n",
    "\n",
    "def multi_map(x,required_cols, area_thresh=150,bfp_per_parcel =2 ):\n",
    "    ret = dict()\n",
    "    req_columns = ['PRCLDMPID', 'building_roi', 'APT'] + required_cols\n",
    "    # get two buildings as we have selected \n",
    "    \n",
    "    \n",
    "    for cols in req_columns:\n",
    "        ret[cols] = x.iloc[0][cols]\n",
    "    \n",
    "    if bfp_per_parcel ==2:\n",
    "        building_polygons = list(x['building_roi'][:2])\n",
    "        geo_area = list(x['building_roi'].apply(lambda poly: abs(geod.geometry_area_perimeter(poly)[0])))[:bfp_per_parcel]\n",
    "        area_diff = geo_area[0] - geo_area[1]\n",
    "        \n",
    "        if area_diff > 0:\n",
    "            if area_diff > area_thresh:\n",
    "                ret['building_roi'] = building_polygons[0]\n",
    "            else:\n",
    "                ret['building_roi'] = (list(x['building_roi'][:bfp_per_parcel])[get_nearest_poly(list(x['APT'])[0], building_polygons)])\n",
    "\n",
    "        elif area_diff <= 0:\n",
    "            if np.abs(area_diff) > area_thresh:\n",
    "                ret['building_roi'] = building_polygons[1]\n",
    "            else:\n",
    "                ret['building_roi'] = (list(x['building_roi'][:bfp_per_parcel])[get_nearest_poly(list(x['APT'])[0], building_polygons)])\n",
    "    \n",
    "    if bfp_per_parcel>2:\n",
    "        building_polygons = list(x['building_roi'][:3])\n",
    "        mnr_apt = list(x['APT'])[0]\n",
    "        point_on_polygon = False\n",
    "        \n",
    "        for polygon in building_polygons:\n",
    "            if check_point_on_polygon(polygon,mnr_apt):\n",
    "                point_on_polygon=True \n",
    "        if not point_on_polygon:\n",
    "            ret['building_roi'] = (list(x['building_roi'][:3])[get_nearest_poly(mnr_apt, building_polygons)])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apt_to_bfp_distance(self, data):\n",
    "    anchor_point = data['APT']\n",
    "    bfp_centroid = data['updated_geometries']\n",
    "    return get_distance(anchor_point, bfp_centroid)\n",
    "\n",
    "complexity = 2 \n",
    "\n",
    "if complexity ==1 :\n",
    "    process_df['updated_geometries'] = process_df['building_roi'].apply(lambda x: x.centroid)\n",
    "    process_df['updated_dt'] = process_df.apply(lambda x: get_apt_to_bfp_distance(x),axis=1)\n",
    "\n",
    "# if complexity ==2 :\n",
    "#     process_df = process_df.groupby(['PRCLDMPID'], as_index=False).apply(lambda x: pd.Series(multi_map(x,required_cols=cols)))\n",
    "\n",
    "filter_df = process_df.groupby(['PRCLDMPID'], as_index=False).apply(lambda x: pd.Series(multi_map(x,required_cols=cols,bfp_per_parcel=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filter_df.shape)\n",
    "filter_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Geospartial data without Parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import os.path as osp\n",
    "import warnings\n",
    "from urllib.parse import quote\n",
    "import logging\n",
    "import pandas as pd \n",
    "import shapely.geos\n",
    "\n",
    "import geopandas as gpd\n",
    "from pyproj import Geod\n",
    "from shapely import wkt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BASE_PATH = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data\" \n",
    "mnr_apt = osp.join(BASE_PATH,\"California/APT__2023_03_000_nam_usa_uca.csv\")\n",
    "BFP_PATH = osp.join(BASE_PATH,\"California/California.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vector_data(vector_file):\n",
    "    if not os.path.isfile(vector_file):\n",
    "        logging.error(\"{} file not found\".format(vector_file))\n",
    "        return\n",
    "    vector_df = gpd.read_file(vector_file)\n",
    "    vector_df = gpd.GeoDataFrame(vector_df, crs=\"EPSG:4326\", geometry='geometry')\n",
    "    vector_df = vector_df.to_crs(\"epsg:4326\")\n",
    "    return vector_df\n",
    "\n",
    "def save_dataframe_as_csv(pd_dataframe:pd.DataFrame,filename='results.csv',index_name= 'geometry'):\n",
    "    pd_dataframe['coordinates'] = gpd.GeoSeries.from_wkt(pd_dataframe[index_name])\n",
    "    pd_dataframe = pd_dataframe.drop(index_name, axis=1)\n",
    "    geo_dataframe = gpd.GeoDataFrame(pd_dataframe, geometry='coordinates', crs=\"EPSG:4326\")\n",
    "    filename = os.path.join(filename)\n",
    "    geo_dataframe.to_csv(filename,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read MNR APT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11394562, 17) EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "apt_data = pd.read_csv(mnr_apt,index_col=False)\n",
    "apt_data['geometry'] = apt_data['coordinates'].apply(wkt.loads)\n",
    "apt_gdf = gpd.GeoDataFrame(apt_data,crs=\"EPSG:4326\", geometry='geometry')\n",
    "\n",
    "print(\"{} {}\".format(apt_gdf.shape,apt_gdf.crs))\n",
    "apt_gdf.head(4)\n",
    "\n",
    "del apt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>feat_id</th>\n",
       "      <th>iso_script</th>\n",
       "      <th>iso_lang_code</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>house_number</th>\n",
       "      <th>state_province_code</th>\n",
       "      <th>locality</th>\n",
       "      <th>street_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>prefix</th>\n",
       "      <th>suffix</th>\n",
       "      <th>predir</th>\n",
       "      <th>postdir</th>\n",
       "      <th>sn_body</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00005543-3100-2800-0000-00000000443d</td>\n",
       "      <td>Latn</td>\n",
       "      <td>ENG</td>\n",
       "      <td>93012-5539</td>\n",
       "      <td>1348</td>\n",
       "      <td>CA</td>\n",
       "      <td>Camarillo</td>\n",
       "      <td>El Lazo Ct</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Lazo</td>\n",
       "      <td>POINT (-118.988968 34.230556)</td>\n",
       "      <td>POINT (-118.98897 34.23056)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00005543-3100-2800-0000-00000000443e</td>\n",
       "      <td>Latn</td>\n",
       "      <td>ENG</td>\n",
       "      <td>93012-5539</td>\n",
       "      <td>1344</td>\n",
       "      <td>CA</td>\n",
       "      <td>Camarillo</td>\n",
       "      <td>El Lazo Ct</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Lazo</td>\n",
       "      <td>POINT (-118.989011 34.230623)</td>\n",
       "      <td>POINT (-118.98901 34.23062)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00005543-3100-2800-0000-00000000443f</td>\n",
       "      <td>Latn</td>\n",
       "      <td>ENG</td>\n",
       "      <td>93012-5539</td>\n",
       "      <td>1352</td>\n",
       "      <td>CA</td>\n",
       "      <td>Camarillo</td>\n",
       "      <td>El Lazo Ct</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Lazo</td>\n",
       "      <td>POINT (-118.988926 34.230498)</td>\n",
       "      <td>POINT (-118.98893 34.23050)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00005543-3100-2800-0000-000000004440</td>\n",
       "      <td>Latn</td>\n",
       "      <td>ENG</td>\n",
       "      <td>93012-5539</td>\n",
       "      <td>1340</td>\n",
       "      <td>CA</td>\n",
       "      <td>Camarillo</td>\n",
       "      <td>El Lazo Ct</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Lazo</td>\n",
       "      <td>POINT (-118.989052 34.230677)</td>\n",
       "      <td>POINT (-118.98905 34.23068)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00005543-3100-2800-0000-000000004441</td>\n",
       "      <td>Latn</td>\n",
       "      <td>ENG</td>\n",
       "      <td>93012-5539</td>\n",
       "      <td>1356</td>\n",
       "      <td>CA</td>\n",
       "      <td>Camarillo</td>\n",
       "      <td>El Lazo Ct</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Lazo</td>\n",
       "      <td>POINT (-118.988667 34.230437)</td>\n",
       "      <td>POINT (-118.98867 34.23044)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               feat_id iso_script iso_lang_code  \\\n",
       "0           0  00005543-3100-2800-0000-00000000443d       Latn           ENG   \n",
       "1           1  00005543-3100-2800-0000-00000000443e       Latn           ENG   \n",
       "2           2  00005543-3100-2800-0000-00000000443f       Latn           ENG   \n",
       "3           3  00005543-3100-2800-0000-000000004440       Latn           ENG   \n",
       "4           4  00005543-3100-2800-0000-000000004441       Latn           ENG   \n",
       "\n",
       "  postal_code house_number state_province_code   locality street_name  \\\n",
       "0  93012-5539         1348                  CA  Camarillo  El Lazo Ct   \n",
       "1  93012-5539         1344                  CA  Camarillo  El Lazo Ct   \n",
       "2  93012-5539         1352                  CA  Camarillo  El Lazo Ct   \n",
       "3  93012-5539         1340                  CA  Camarillo  El Lazo Ct   \n",
       "4  93012-5539         1356                  CA  Camarillo  El Lazo Ct   \n",
       "\n",
       "  country_code prefix suffix predir postdir  sn_body  \\\n",
       "0          USA    NaN     Ct    NaN     NaN  El Lazo   \n",
       "1          USA    NaN     Ct    NaN     NaN  El Lazo   \n",
       "2          USA    NaN     Ct    NaN     NaN  El Lazo   \n",
       "3          USA    NaN     Ct    NaN     NaN  El Lazo   \n",
       "4          USA    NaN     Ct    NaN     NaN  El Lazo   \n",
       "\n",
       "                     coordinates                     geometry  \n",
       "0  POINT (-118.988968 34.230556)  POINT (-118.98897 34.23056)  \n",
       "1  POINT (-118.989011 34.230623)  POINT (-118.98901 34.23062)  \n",
       "2  POINT (-118.988926 34.230498)  POINT (-118.98893 34.23050)  \n",
       "3  POINT (-118.989052 34.230677)  POINT (-118.98905 34.23068)  \n",
       "4  POINT (-118.988667 34.230437)  POINT (-118.98867 34.23044)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt_gdf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MSFT-BFP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11158292, 2) epsg:4326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-119.67270 34.41844, -119.67288 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-119.67254 34.41853, -119.67269 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-119.67196 34.41895, -119.67206 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((-119.67229 34.41889, -119.67209 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((-119.67118 34.41869, -119.67107 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-119.67380 34.41770, -119.67379 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>POLYGON ((-119.67428 34.41947, -119.67409 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-119.67078 34.41878, -119.67088 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>POLYGON ((-119.67364 34.41831, -119.67354 34.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>POLYGON ((-119.67585 34.41953, -119.67595 34.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FID                                           geometry\n",
       "0    0  POLYGON ((-119.67270 34.41844, -119.67288 34.4...\n",
       "1    1  POLYGON ((-119.67254 34.41853, -119.67269 34.4...\n",
       "2    2  POLYGON ((-119.67196 34.41895, -119.67206 34.4...\n",
       "3    3  POLYGON ((-119.67229 34.41889, -119.67209 34.4...\n",
       "4    4  POLYGON ((-119.67118 34.41869, -119.67107 34.4...\n",
       "5    5  POLYGON ((-119.67380 34.41770, -119.67379 34.4...\n",
       "6    6  POLYGON ((-119.67428 34.41947, -119.67409 34.4...\n",
       "7    7  POLYGON ((-119.67078 34.41878, -119.67088 34.4...\n",
       "8    8  POLYGON ((-119.67364 34.41831, -119.67354 34.4...\n",
       "9    9  POLYGON ((-119.67585 34.41953, -119.67595 34.4..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfp_data = read_vector_data(BFP_PATH)\n",
    "print(\"{} {}\".format(bfp_data.shape,bfp_data.crs))\n",
    "bfp_data.head(10)\n",
    "# bfp_data['coordinates'] = bfp_data.geometry.apply(lambda x: wkt.dumps(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process for nearest Buildings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def __get_buildingfootprint(val):\n",
    "    return bfp_data['geometry'].loc[val]\n",
    "\n",
    "def get_apt_roi(data):\n",
    "    building_polygon = data['building_geometry']\n",
    "    apt_point = data['geometry']\n",
    "    apt_on_bfp = None\n",
    "    try:\n",
    "        if building_polygon ==np.nan:\n",
    "            apt_on_bfp = None\n",
    "        elif building_polygon.contains(apt_point):\n",
    "            apt_on_bfp = 1\n",
    "        else:\n",
    "            apt_on_bfp = 0 \n",
    "    except shapely.geos.TopologicalError as err:\n",
    "        logging.error(\"{} for {}\".format(err, building_polygon))\n",
    "\n",
    "sample_apt_gdf = apt_gdf.sample(50000)\n",
    "print(type(sample_apt_gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_within_building = gpd.sjoin(sample_apt_gdf,bfp_data, op='within',how='left')#op='intersects')\n",
    "apt_within_building = apt_within_building.dropna() \n",
    "\n",
    "apt_within_building.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_within_building['building_geometry'] = apt_within_building['index_right'].apply(lambda x: __get_buildingfootprint(x))\n",
    "\n",
    "apt_within_building['building_roi'] = apt_within_building.apply(lambda x: get_apt_roi(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_within_building.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70ce54ad97a74852893fb3a2eed7fab00a48abaab9c8d77c9e0b6a3e4b45b116"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
