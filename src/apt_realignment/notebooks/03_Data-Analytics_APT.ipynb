{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49628c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys \n",
    "import pandas as pd \n",
    "import gc\n",
    "from shapely import wkt\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point,mapping,Polygon,box,MultiPoint\n",
    "import geopandas as gpd \n",
    "import seaborn as sns \n",
    " \n",
    "# for parallelization\n",
    "sys.path.append('/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/src/apt_realignment')\n",
    "from process_geometries import ProcessGeometricData  as ProcessAPT_data\n",
    "from utils.haversine_distance import get_distance\n",
    "from utils.geometric_utils import geojson2shpfile\n",
    "\n",
    "\n",
    "def save_geometry(dataframe,geometry,out_path,fname='dataframe.geojson'):\n",
    "    df_to_save = gpd.GeoDataFrame(geometry=dataframe[geometry],crs=\"EPSG:4326\")\n",
    "    df_to_save = df_to_save.to_crs(\"epsg:4326\")\n",
    "    df_to_save.to_file(os.path.join(out_path,fname),driver=\"GeoJSON\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87320cab",
   "metadata": {},
   "source": [
    "## Download Parcel Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040d122b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stname</th>\n",
       "      <th>st</th>\n",
       "      <th>stusps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>4</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>6</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stname   st  stusps\n",
       "0     Alabama    1      AL\n",
       "1      Alaska    2      AK\n",
       "2     Arizona    4      AZ\n",
       "3    Arkansas    5      AR\n",
       "4  California    6      CA"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "import urllib\n",
    "\n",
    "FIPS_CSV_PATH = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/us-state-ansi-fips.csv\"\n",
    "ALL_FIPS = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/All_counties_code.csv\"\n",
    "\n",
    "data_path = \"mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/\"\n",
    "\n",
    "fips_df = pd.read_csv(FIPS_CSV_PATH)\n",
    "fips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce35ba35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips            name state\n",
       "0     0   UNITED STATES   NaN\n",
       "1  1000         ALABAMA   NaN\n",
       "2  1001  Autauga County    AL\n",
       "3  1003  Baldwin County    AL\n",
       "4  1005  Barbour County    AL"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIPSCode_df = pd.read_csv(ALL_FIPS)\n",
    "FIPSCode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79931eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County FIPS Code :  53\n",
      "County Name Code :  WA\n",
      "mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/Washington\n"
     ]
    }
   ],
   "source": [
    "County = 'Washington'\n",
    "\n",
    "county_info = fips_df.loc[fips_df['stname']==County]\n",
    "\n",
    "data = county_info.values.tolist()[0]\n",
    "\n",
    "print(\"County FIPS Code : \",data[1])\n",
    "print(\"County Name Code : \",data[2].strip())\n",
    "\n",
    "out_path = os.path.join(data_path,County)\n",
    "\n",
    "if not os.path.isdir(out_path):\n",
    "    os.mkdir(out_path)\n",
    "\n",
    "print(out_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9c04049",
   "metadata": {},
   "source": [
    "## Get All Counties of Texas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2f44d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIPS found: 39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['53001',\n",
       " '53003',\n",
       " '53005',\n",
       " '53007',\n",
       " '53009',\n",
       " '53011',\n",
       " '53013',\n",
       " '53015',\n",
       " '53017',\n",
       " '53019',\n",
       " '53021',\n",
       " '53023',\n",
       " '53025',\n",
       " '53027',\n",
       " '53029',\n",
       " '53031',\n",
       " '53033',\n",
       " '53035',\n",
       " '53037',\n",
       " '53039',\n",
       " '53041',\n",
       " '53043',\n",
       " '53045',\n",
       " '53047',\n",
       " '53049',\n",
       " '53051',\n",
       " '53053',\n",
       " '53055',\n",
       " '53057',\n",
       " '53059',\n",
       " '53061',\n",
       " '53063',\n",
       " '53065',\n",
       " '53067',\n",
       " '53069',\n",
       " '53071',\n",
       " '53073',\n",
       " '53075',\n",
       " '53077']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fipss = list(map(lambda x: str(x),list(FIPSCode_df['fips'].loc[FIPSCode_df['state']==data[2].strip()])))\n",
    "fipss = list(map(lambda x: \"0{}\".format(x) if len(x)==4 else x ,fipss))\n",
    "\n",
    "print('FIPS found:',len(fipss))\n",
    "fipss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d096594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "errors = set()\n",
    "for fips in tqdm(fipss,total=len(fipss)):    \n",
    "    if not os.path.isfile(os.path.join(out_path,f\"Parcels_{fips}.zip\")):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/July%202018/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/parcels/Parcels_{fips}.zip\")\n",
    "        except:\n",
    "            try:\n",
    "                urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/April%202018/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/parcels/Parcels_{fips}.zip\")\n",
    "            except:\n",
    "                try:\n",
    "\n",
    "                    urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/Jan%202018/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/parcels/Parcels_{fips}.zip\")\n",
    "                except:\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/Oct%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/parcels/Parcels_{fips}.zip\")\n",
    "                    except:\n",
    "                        try:\n",
    "                            urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/July%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/parcels/Parcels_{fips}.zip\")\n",
    "                        except:\n",
    "                            try:\n",
    "                                urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/April%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/parcels/Parcels_{fips}.zip\")\n",
    "                            except:\n",
    "                                try:\n",
    "                                    urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/Jan%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/parcels/Parcels_{fips}.zip\")\n",
    "                                except:\n",
    "                                    print(\"No information for :\",fips)\n",
    "                                    errors.add(fips)\n",
    "                                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "errors = set()\n",
    "\n",
    "for fips in tqdm(fipss):\n",
    "            try:\n",
    "                urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/July%202018/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "            except KeyboardInterrupt as e:\n",
    "                raise e \n",
    "            except:\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/April%202018/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "                except KeyboardInterrupt as e:\n",
    "                    raise e \n",
    "                except:\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/Jan%202018/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "                    except KeyboardInterrupt as e:\n",
    "                        raise e \n",
    "                    except:\n",
    "                        try:\n",
    "                            urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/Oct%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "                        except KeyboardInterrupt as e:\n",
    "                            raise e \n",
    "                        except:\n",
    "                            try: \n",
    "                                urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/July%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "                            except KeyboardInterrupt as e:\n",
    "                                raise e \n",
    "                            except:\n",
    "                                try:\n",
    "                                    urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/April%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "                                except KeyboardInterrupt as e:\n",
    "                                    raise e \n",
    "                                except:\n",
    "                                    try:\n",
    "                                        urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/Jan%202017/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "                                    except KeyboardInterrupt as e:\n",
    "                                        raise e \n",
    "                                    except:\n",
    "                                        try:\n",
    "                                            urllib.request.urlretrieve(f\"https://sts-rescat-prod.s3-eu-west-1.amazonaws.com/Rescat/Global/Active/USA_Nation/USA000003213/AUTHORIZED%20USERS%20ONLY/Oct%202016/Parcels_{fips}.zip\", f\"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/data/{County}/Parcels_{fips}.zip\")\n",
    "                                        except KeyboardInterrupt as e:\n",
    "                                            raise e \n",
    "                                        except:\n",
    "                                            print(\"No data for : \",fips)\n",
    "                                            errors.add(fips)\n",
    "                                            continue\n",
    "            try:\n",
    "                print(\"downloded : \",fips)\n",
    "                # gdf = gpd.read_file(f'parcels_for_postgress/Parcels_{fips}.shp').to_crs(3857)\n",
    "                # gdf['state'] = state\n",
    "                # gdf.to_crs(3857, inplace=True)\n",
    "                # gdf.to_postgis(name=\"land_parcels\", schema='dev_ppa', con=con, index=False, if_exists='append')\n",
    "            except KeyboardInterrupt as e:\n",
    "                raise e \n",
    "            except:\n",
    "                errors.add(fips)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0132462",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "pkl_path = osp.join(data_path,state,city,'Apt_realignment')\n",
    "pkl_files = glob(pkl_path+'/*/*.pkl')\n",
    "print(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bfb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Show single bfp within Parcel data\n",
    "df_one_bfp = pd.read_pickle(pkl_files[0])\n",
    "df_one_bfp = df_one_bfp.reset_index(drop=True)\n",
    "print(\"simple scenario sahpe\",df_one_bfp.shape[0])\n",
    "\n",
    "df_two_bfp = pd.read_pickle(pkl_files[1])\n",
    "df_two_bfp = df_two_bfp.reset_index(drop=True)\n",
    "print(\" complx scenario shape:\",df_two_bfp.shape[0])\n",
    "\n",
    "merge_df= pd.concat([df_one_bfp,df_two_bfp])\n",
    "print(\"Merged Shape\",merge_df.shape)\n",
    "merge_df.to_pickle(os.path.join(pkl_path,'FinalUpdated_APT_{}_{}.pkl'.format(state,city)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09af0da",
   "metadata": {},
   "source": [
    "## IIlunois Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys \n",
    "import pycoredb \n",
    "import pandas as pd \n",
    "import gc\n",
    "from shapely import wkt\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point,mapping,Polygon,box,MultiPoint\n",
    "import geopandas as gpd \n",
    "import seaborn as sns \n",
    " \n",
    "# for parallelization\n",
    "sys.path.append('/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/src/apt_realignment')\n",
    "from process_geometries import ProcessGeometricData  as ProcessAPT_data\n",
    "from utils.haversine_distance import get_distance\n",
    "from utils.geometric_utils import geojson2shpfile\n",
    "\n",
    "data_path  = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/BFP_Analysis_USA/data/data\"\n",
    "state = \"Illinois\"\n",
    "city = \"cook\"\n",
    "apt_data_path = os.path.join(data_path,state,\"APT__2022_09_001_nam_usa_uil.shp\" )\n",
    "parcel_path = os.path.join(data_path,state,city,\"Parcels_17031/Parcels_17031.shp\")\n",
    "building_geojson = os.path.join(data_path,state,'Illinois.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson2shpfile(building_geojson,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5de7a1",
   "metadata": {},
   "source": [
    "### Single BFP within a Parcel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_path,state,city,'Apt_realignment') \n",
    "apt_preprocess = ProcessAPT_data(parcel_shapefile=parcel_path,\n",
    "                building_shapefile=building_geojson,\n",
    "                apt_shape_file=apt_data_path , \n",
    "                output_path=output_path)\n",
    "\n",
    "processed_df_cook = apt_preprocess.process_dataframe(bfp_count_per_parcel=1,filename='APT_realigned_usa_il_cook')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_df_cook.shape[0])\n",
    "processed_df_cook.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9792625",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_greater_than_50m = processed_df_cook.loc[processed_df_cook['APT_to_Centroid_distance']>50].shape[0]\n",
    "print(\"Data points greater than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_cook.shape[0])))\n",
    "\n",
    "distance_greater_than_50m = processed_df_cook.loc[processed_df_cook['APT_to_Centroid_distance']<50].shape[0]\n",
    "print(\"Data points less than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_cook.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,9))\n",
    "\n",
    "ax.set_title(\"Histogram of APT to centroid distance on/not on BFP\")\n",
    "ax.set_xlabel(\"APT point to centroid distance(meters)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "frqTrue, edgesTrue = np.histogram(processed_df_cook['APT_to_Centroid_distance'].loc[processed_df_cook['APT_to_Centroid_distance']<150].values, bins = np.arange(0,150,10))\n",
    "p1 = ax.bar(edgesTrue[:-1], frqTrue, width=np.diff(edgesTrue), edgecolor=\"black\", align=\"edge\",alpha=0.4,label='Address Points on Rooftop',color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088bb3d",
   "metadata": {},
   "source": [
    "#### Two BFP's within a Parcel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d664a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process complexity 2-- 2 bfp \n",
    "\n",
    "output_path = os.path.join(data_path,state,city,'Apt_realignment') \n",
    "apt_preprocess = ProcessAPT_data(parcel_shapefile=parcel_path,\n",
    "                building_shapefile=building_geojson,\n",
    "                apt_shape_file=apt_data_path , \n",
    "                output_path=output_path)\n",
    "\n",
    "processed_df_cook = apt_preprocess.process_dataframe(bfp_count_per_parcel=2,filename='APT_realigned_usa_uil_cook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b167943",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_df_cook.shape[0])\n",
    "processed_df_cook.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc08df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_greater_than_50m = processed_df_cook.loc[processed_df_cook['APT_to_Centroid_distance']>50].shape[0]\n",
    "print(\"Data points greater than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_cook.shape[0])))\n",
    "\n",
    "distance_greater_than_50m = processed_df_cook.loc[processed_df_cook['APT_to_Centroid_distance']<50].shape[0]\n",
    "print(\"Data points less than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_cook.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,9))\n",
    "\n",
    "ax.set_title(\"Histogram of APT to centroid distance on/not on BFP\")\n",
    "ax.set_xlabel(\"APT point to centroid distance(meters)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "frqTrue, edgesTrue = np.histogram(processed_df_cook['APT_to_Centroid_distance'].loc[processed_df_cook['APT_to_Centroid_distance']<150].values, bins = np.arange(0,150,10))\n",
    "p1 = ax.bar(edgesTrue[:-1], frqTrue, width=np.diff(edgesTrue), edgecolor=\"black\", align=\"edge\",alpha=0.4,label='Address Points on Rooftop',color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8693d",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59577a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "pkl_path = osp.join(data_path,state,city,'Apt_realignment')\n",
    "pkl_files = glob(pkl_path+'/*/*.pkl')\n",
    "print(pkl_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show single bfp within Parcel data\n",
    "df_one_bfp = pd.read_pickle(pkl_files[0])\n",
    "df_one_bfp = df_one_bfp.reset_index(drop=True)\n",
    "print(\"simple scenario sahpe\",df_one_bfp.shape[0])\n",
    "\n",
    "df_two_bfp = pd.read_pickle(pkl_files[1])\n",
    "df_two_bfp = df_two_bfp.reset_index(drop=True)\n",
    "print(\" complx scenario shape:\",df_two_bfp.shape[0])\n",
    "\n",
    "merge_df= pd.concat([df_one_bfp,df_two_bfp])\n",
    "print(\"Merged Shape\",merge_df.shape)\n",
    "merge_df.to_pickle(os.path.join(pkl_path,'FinalUpdated_APT_{}_{}.pkl'.format(state,city)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f77b0f",
   "metadata": {},
   "source": [
    "## Michigan Wayne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07939cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys \n",
    "import pycoredb \n",
    "import pandas as pd \n",
    "import gc\n",
    "from shapely import wkt\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point,mapping,Polygon,box,MultiPoint\n",
    "import geopandas as gpd \n",
    "import seaborn as sns \n",
    " \n",
    "# for parallelization\n",
    "sys.path.append('/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/src/apt_realignment')\n",
    "from process_geometries import ProcessGeometricData  as ProcessAPT_data\n",
    "from utils.haversine_distance import get_distance\n",
    "\n",
    "data_path  = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/BFP_Analysis_USA/data/data\"\n",
    "state = \"MI\"\n",
    "city = \"wayne\"\n",
    "apt_data_path = os.path.join(data_path,state,\"APT__2022_09_001_nam_usa_umx.shp\" )\n",
    "parcel_path = os.path.join(data_path,state,city,\"Parcels_26163/Parcels_26163.shp\")\n",
    "building_geojson = os.path.join(data_path,state,'Michigan.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a225c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson2shpfile(building_geojson,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481a168",
   "metadata": {},
   "source": [
    "### Single BFP within a Parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ab049",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_path,state,city,'Apt_realignment') \n",
    "apt_preprocess = ProcessAPT_data(parcel_shapefile=parcel_path,\n",
    "                building_shapefile=building_geojson,\n",
    "                apt_shape_file=apt_data_path , \n",
    "                output_path=output_path)\n",
    "\n",
    "processed_df_wayne = apt_preprocess.process_dataframe(bfp_count_per_parcel=1,filename='APT_realigned_usa_umx_wayne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Shape:\",processed_df_wayne.shape)\n",
    "processed_df_wayne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd853db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_greater_than_50m = processed_df_wayne.loc[processed_df_wayne['APT_to_Centroid_distance']>50].shape[0]\n",
    "print(\"Data points greater than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_wayne.shape[0])))\n",
    "\n",
    "distance_greater_than_50m = processed_df_wayne.loc[processed_df_wayne['APT_to_Centroid_distance']<50].shape[0]\n",
    "print(\"Data points less than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_wayne.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,9))\n",
    "\n",
    "ax.set_title(\"Histogram of APT to centroid distance on/not on BFP\")\n",
    "ax.set_xlabel(\"APT point to centroid distance(meters)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "frqTrue, edgesTrue = np.histogram(processed_df_wayne['APT_to_Centroid_distance'].loc[processed_df_wayne['APT_to_Centroid_distance']<150].values, bins = np.arange(0,150,10))\n",
    "p1 = ax.bar(edgesTrue[:-1], frqTrue, width=np.diff(edgesTrue), edgecolor=\"black\", align=\"edge\",alpha=0.4,label='Address Points on Rooftop',color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165cb0a7",
   "metadata": {},
   "source": [
    "#### Two BFP's within a Parcel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b034da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_path,state,city,'Apt_realignment') \n",
    "apt_preprocess = ProcessAPT_data(parcel_shapefile=parcel_path,\n",
    "                building_shapefile=building_geojson,\n",
    "                apt_shape_file=apt_data_path , \n",
    "                output_path=output_path)\n",
    "\n",
    "processed_df_wayne = apt_preprocess.process_dataframe(bfp_count_per_parcel=2,filename='APT_realigned_usa_umx_wayne')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e294bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_df_wayne.shape[0])\n",
    "processed_df_wayne.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c25d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_greater_than_50m = processed_df_wayne.loc[processed_df_wayne['APT_to_Centroid_distance']>50].shape[0]\n",
    "print(\"Data points greater than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_wayne.shape[0])))\n",
    "\n",
    "distance_greater_than_50m = processed_df_wayne.loc[processed_df_wayne['APT_to_Centroid_distance']<50].shape[0]\n",
    "print(\"Data points less than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_wayne.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,9))\n",
    "\n",
    "ax.set_title(\"Histogram of APT to centroid distance on/not on BFP\")\n",
    "ax.set_xlabel(\"APT point to centroid distance(meters)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "frqTrue, edgesTrue = np.histogram(processed_df_wayne['APT_to_Centroid_distance'].loc[processed_df_wayne['APT_to_Centroid_distance']<150].values, bins = np.arange(0,150,10))\n",
    "p1 = ax.bar(edgesTrue[:-1], frqTrue, width=np.diff(edgesTrue), edgecolor=\"black\", align=\"edge\",alpha=0.4,label='Address Points on Rooftop',color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eddd436",
   "metadata": {},
   "source": [
    "### Merge both data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os\n",
    "import os.path as osp \n",
    "pkl_path = osp.join(data_path,state,city,'Apt_realignment')\n",
    "pkl_files = glob(pkl_path+'/*/*.pkl')\n",
    "print(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfef001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Show single bfp within Parcel data\n",
    "df_one_bfp = pd.read_pickle(pkl_files[0])\n",
    "df_one_bfp = df_one_bfp.reset_index(drop=True)\n",
    "print(\"simple scenario sahpe\",df_one_bfp.shape[0])\n",
    "\n",
    "df_two_bfp = pd.read_pickle(pkl_files[1])\n",
    "df_two_bfp = df_two_bfp.reset_index(drop=True)\n",
    "print(\" complx scenario shape:\",df_two_bfp.shape[0])\n",
    "\n",
    "merge_df= pd.concat([df_one_bfp,df_two_bfp])\n",
    "print(\"Merged Shape\",merge_df.shape)\n",
    "merge_df.to_pickle(os.path.join(pkl_path,'FinalUpdated_APT_{}_{}.pkl'.format(state,city)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16962906",
   "metadata": {},
   "source": [
    "## Dallas Texas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c812e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys \n",
    "import pycoredb \n",
    "import pandas as pd \n",
    "import gc\n",
    "from shapely import wkt\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point,mapping,Polygon,box,MultiPoint\n",
    "import geopandas as gpd \n",
    "import seaborn as sns \n",
    " \n",
    "# for parallelization\n",
    "sys.path.append('/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/src/apt_realignment')\n",
    "from process_geometries import ProcessGeometricData  as ProcessAPT_data\n",
    "from utils.haversine_distance import get_distance\n",
    "\n",
    "data_path  = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/BFP_Analysis_USA/data/data\"\n",
    "state = \"Texas\"\n",
    "city = \"Dallas\"\n",
    "apt_data_path = os.path.join(data_path,state,\"APT_2022_09_000_nam_usa_utx.shp\" )\n",
    "parcel_path = os.path.join(data_path,state,city,\"Parcels_48113/Parcels_48113.shp\")\n",
    "building_geojson = os.path.join(data_path,state,'Texas.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a53c68",
   "metadata": {},
   "source": [
    "### Single BFP within Parcel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_path,state,city,'Apt_realignment') \n",
    "apt_preprocess = ProcessAPT_data(parcel_shapefile=parcel_path,\n",
    "                building_shapefile=building_geojson,\n",
    "                apt_shape_file=apt_data_path , \n",
    "                output_path=output_path)\n",
    "\n",
    "processed_df_dallas = apt_preprocess.process_dataframe(bfp_count_per_parcel=1,filename='APT_realigned_usa_utx_dallas')\n",
    "processed_df_dallas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc52879",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_greater_than_50m = processed_df_dallas.loc[processed_df_dallas['APT_to_Centroid_distance']>50].shape[0]\n",
    "print(\"Data points greater than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_dallas.shape[0])))\n",
    "\n",
    "distance_greater_than_50m = processed_df_dallas.loc[processed_df_dallas['APT_to_Centroid_distance']<50].shape[0]\n",
    "print(\"Data points less than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_dallas.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2de6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,9))\n",
    "\n",
    "ax.set_title(\"Histogram of APT to centroid distance on/not on BFP\")\n",
    "ax.set_xlabel(\"APT point to centroid distance(meters)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "frqTrue, edgesTrue = np.histogram(processed_df_dallas['APT_to_Centroid_distance'].loc[processed_df_dallas['APT_to_Centroid_distance']<50].values, bins = np.arange(2,50,5))\n",
    "p1 = ax.bar(edgesTrue[:-1], frqTrue, width=np.diff(edgesTrue), edgecolor=\"black\", align=\"edge\",alpha=0.4,label='Address Points on Rooftop',color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9b8b4",
   "metadata": {},
   "source": [
    "### Two BFP within Parcel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41531015",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_path,state,city,'Apt_realignment') \n",
    "apt_preprocess = ProcessAPT_data(parcel_shapefile=parcel_path,building_shapefile=building_geojson,\n",
    "                                    apt_shape_file=apt_data_path , output_path=output_path)\n",
    "\n",
    "processed_df_dallas = apt_preprocess.process_dataframe(bfp_count_per_parcel=2,filename='APT_realigned_usa_utx_dallas')\n",
    "processed_df_dallas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_greater_than_50m = processed_df_dallas.loc[processed_df_dallas['APT_to_Centroid_distance']>50].shape[0]\n",
    "print(\"Data points greater than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_dallas.shape[0])))\n",
    "\n",
    "distance_greater_than_50m = processed_df_dallas.loc[processed_df_dallas['APT_to_Centroid_distance']<50].shape[0]\n",
    "print(\"Data points less than 50m: {:.2f}%\".format(100*(distance_greater_than_50m/processed_df_dallas.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a48865",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,9))\n",
    "\n",
    "ax.set_title(\"Histogram of APT to centroid distance on/not on BFP\")\n",
    "ax.set_xlabel(\"APT point to centroid distance(meters)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "frqTrue, edgesTrue = np.histogram(processed_df_dallas['APT_to_Centroid_distance'].loc[processed_df_dallas['APT_to_Centroid_distance']<50].values, bins = np.arange(2,50,5))\n",
    "p1 = ax.bar(edgesTrue[:-1], frqTrue, width=np.diff(edgesTrue), edgecolor=\"black\", align=\"edge\",alpha=0.4,label='Address Points on Rooftop',color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24baf7e2",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d84736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "pkl_path = osp.join(data_path,state,city,'Apt_realignment')\n",
    "pkl_files = glob(pkl_path+'/*/*.pkl')\n",
    "print(pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Show single bfp within Parcel data\n",
    "df_one_bfp = pd.read_pickle(pkl_files[0])\n",
    "df_one_bfp = df_one_bfp.reset_index(drop=True)\n",
    "print(\"simple scenario sahpe\",df_one_bfp.shape[0])\n",
    "\n",
    "df_two_bfp = pd.read_pickle(pkl_files[1])\n",
    "df_two_bfp = df_two_bfp.reset_index(drop=True)\n",
    "print(\" complx scenario shape:\",df_two_bfp.shape[0])\n",
    "\n",
    "merge_df= pd.concat([df_one_bfp,df_two_bfp])\n",
    "print(\"Merged Shape\",merge_df.shape)\n",
    "merge_df.to_pickle(os.path.join(pkl_path,'FinalUpdated_APT_{}_{}.pkl'.format(state,city)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6d215",
   "metadata": {},
   "source": [
    "### Compare MNR data with MSFT dBFP ata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys \n",
    "\n",
    "import pycoredb \n",
    "import pandas as pd \n",
    "import gc\n",
    "\n",
    "from shapely import wkt\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point,mapping,Polygon,box,MultiPoint\n",
    "import geopandas as gpd \n",
    "import seaborn as sns \n",
    "\n",
    "# for parallelization\n",
    "sys.path.append('/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/APT-Realignment/src/apt_realignment')\n",
    "from process_geometries import ProcessGeometricData  as ProcessAPT_data\n",
    "from utils.haversine_distance import get_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30078a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path  = \"/mnt/c/Users/tandon/OneDrive - TomTom/Desktop/tomtom/Workspace/01_Rooftop_accuracy/BFP_Analysis_USA/data/data\"\n",
    "state = \"Texas\"\n",
    "building_geojson = os.path.join(data_path,state,'Texas.geojson')\n",
    "mnr_building_geojson = os.path.join(data_path,state,'BFP__2022_09_012_nam_usa_utx.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bced8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfp_df = gpd.read_file(building_geojson)\n",
    "bfp_df = gpd.GeoDataFrame(bfp_df,crs=\"EPSG:4326\",geometry='geometry')\n",
    "bfp_df = bfp_df.to_crs(\"epsg:4326\")\n",
    "print(\"Total number of data points collected from MNR database \",bfp_df.shape[0])\n",
    "gc.collect()\n",
    "bfp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnr_bfp_df = gpd.read_file(mnr_building_geojson)\n",
    "mnr_bfp_df = gpd.GeoDataFrame(mnr_bfp_df,crs=\"EPSG:4326\",geometry='geometry')\n",
    "mnr_bfp_df = mnr_bfp_df.to_crs(\"epsg:4326\")\n",
    "print(\"Total number of data points collected from MNR database \",mnr_bfp_df.shape[0])\n",
    "gc.collect()\n",
    "mnr_bfp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78399ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buildingfootprint(val):\n",
    "    return bfp_df['geometry'].loc[val]\n",
    "\n",
    "join_df = gpd.sjoin(mnr_bfp_df, bfp_df, op='intersects', how='left')\n",
    "join_df.dropna(inplace=True)\n",
    "join_df['MSFT_building_geom'] = join_df['index_right'].apply(lambda x: get_buildingfootprint(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a89ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buildingfootprint(val):\n",
    "    return bfp_df['geometry'].loc[val]\n",
    "\n",
    "join_df.dropna(inplace=True)\n",
    "join_df['MSFT_building_geom'] = join_df['index_right'].apply(lambda x: get_buildingfootprint(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5289497",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly_iou(data: gpd.GeoSeries):\n",
    "    try:\n",
    "        intersect = data['geometry'].intersection(data['MSFT_building_geom']).area\n",
    "        union = data['geometry'].union(data['MSFT_building_geom']).area\n",
    "        iou = intersect / union\n",
    "    except:\n",
    "        iou = None\n",
    "    return iou\n",
    "join_df['IOU'] = join_df.apply(lambda x: get_poly_iou(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4cb985",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.dropna(inplace=True)\n",
    "print(join_df['IOU'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425b2d0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pygeo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "70ce54ad97a74852893fb3a2eed7fab00a48abaab9c8d77c9e0b6a3e4b45b116"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
